{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "941afe12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T19:31:01.742913Z",
     "iopub.status.busy": "2025-02-06T19:31:01.742600Z",
     "iopub.status.idle": "2025-02-06T19:31:10.454108Z",
     "shell.execute_reply": "2025-02-06T19:31:10.452987Z"
    },
    "id": "cLets_wxNhpW",
    "papermill": {
     "duration": 8.718844,
     "end_time": "2025-02-06T19:31:10.455801",
     "exception": false,
     "start_time": "2025-02-06T19:31:01.736957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install ultralytics\n",
    "!pip install ensemble-boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eff92710",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T19:31:10.469612Z",
     "iopub.status.busy": "2025-02-06T19:31:10.469284Z",
     "iopub.status.idle": "2025-02-06T19:31:20.866637Z",
     "shell.execute_reply": "2025-02-06T19:31:20.865998Z"
    },
    "id": "L-kqQjhnNhpX",
    "outputId": "2e4808e6-7cff-4110-a55b-a7d6950839d4",
    "papermill": {
     "duration": 10.407808,
     "end_time": "2025-02-06T19:31:20.868172",
     "exception": false,
     "start_time": "2025-02-06T19:31:10.460364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
      "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import re\n",
    "import matplotlib.patches as patches\n",
    "import os\n",
    "import yaml\n",
    "import json\n",
    "import shutil\n",
    "import torch\n",
    "\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from ensemble_boxes import weighted_boxes_fusion\n",
    "from ultralytics import YOLO\n",
    "import wandb\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "012be155",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T19:31:20.877356Z",
     "iopub.status.busy": "2025-02-06T19:31:20.877140Z",
     "iopub.status.idle": "2025-02-06T19:31:21.736904Z",
     "shell.execute_reply": "2025-02-06T19:31:21.736175Z"
    },
    "id": "YHmRPEG-NhpY",
    "outputId": "bd6245b9-ee51-42f6-8c56-4fee58b4c725",
    "papermill": {
     "duration": 0.865785,
     "end_time": "2025-02-06T19:31:21.738289",
     "exception": false,
     "start_time": "2025-02-06T19:31:20.872504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msaif-sedaoud\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    api_key = \"67c76616e22ff988e55c17cd3e2257b0b71921de\"\n",
    "    wandb.login(key=api_key)\n",
    "except:\n",
    "    print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. '\n",
    "          'Use the Label name as wandb_api. \\nGet your W&B access token from here: https://wandb.ai/authorize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afc9921d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T19:31:21.747904Z",
     "iopub.status.busy": "2025-02-06T19:31:21.747633Z",
     "iopub.status.idle": "2025-02-06T19:31:21.752341Z",
     "shell.execute_reply": "2025-02-06T19:31:21.751772Z"
    },
    "id": "-AG0hI3xNhpY",
    "papermill": {
     "duration": 0.010637,
     "end_time": "2025-02-06T19:31:21.753512",
     "exception": false,
     "start_time": "2025-02-06T19:31:21.742875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    # Path\n",
    "    base_dir = \"/kaggle/input/ghana-crop-disease\"\n",
    "    train_imgs_dir = os.path.join(base_dir, \"images\")\n",
    "    test_imgs_dir = os.path.join(base_dir, \"images\")\n",
    "\n",
    "    # Model\n",
    "    model_name = 'yolov8m.pt'\n",
    "    img_res = 1024 # 2048\n",
    "\n",
    "    # Training\n",
    "    n_folds = 20\n",
    "    selected_folds = [0]\n",
    "    training_params = {\n",
    "        \"epochs\": 40,\n",
    "        \"close_mosaic\": 10,\n",
    "        \"batch\": 12,\n",
    "        \"amp\": True,\n",
    "        \"optimizer\": \"auto\",\n",
    "        \"seed\": 42,\n",
    "        \"device\": [0],\n",
    "        \"verbose\": False,\n",
    "        \"resume\": False,\n",
    "        \"patience\": 20,\n",
    "        \"iou\": 0.5,\n",
    "        \"fliplr\": 0.2,  # Horizontal flip probability\n",
    "        \"degrees\": 0.2,  # Image rotation in degrees\n",
    "        \"translate\": 0.1,  # Translation as a fraction of image size\n",
    "        \"scale\": 0.2,  # Scale range (e.g., Â±50% of the original size)\n",
    "        \"shear\": 0.1,  # Shear angle in degrees\n",
    "        \"hsv_h\": 0.015,  # Adjust hue (fraction)\n",
    "        \"hsv_s\": 0.2,  # Adjust saturation (fraction)\n",
    "        \"hsv_v\": 0.1,  # Adjust value (brightness, fraction)\n",
    "        \"flipud\": 0.2,  # Vertical flip probability\n",
    "        \"mosaic\": 1.0,  # Mosaic augmentation probability\n",
    "        \"erasing\": 0.3,  # Random erasing probability\n",
    "        \"crop_fraction\": 0.3,  # Crop fraction for cropping-based augmentation\n",
    "        \"cos_lr\": True\n",
    "    }\n",
    "\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0111046b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T19:31:21.762438Z",
     "iopub.status.busy": "2025-02-06T19:31:21.762242Z",
     "iopub.status.idle": "2025-02-06T19:31:21.766534Z",
     "shell.execute_reply": "2025-02-06T19:31:21.765936Z"
    },
    "id": "o6AZm3OiNhpY",
    "papermill": {
     "duration": 0.010127,
     "end_time": "2025-02-06T19:31:21.767799",
     "exception": false,
     "start_time": "2025-02-06T19:31:21.757672",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_class_counts(train_df):\n",
    "    class_counts = {image_id: {i: 0 for i in range(1, config.num_classes+1)} for image_id in train_df[\"Image_ID\"].unique()}\n",
    "    for image_id in tqdm(train_df[\"Image_ID\"].unique(), desc='Preparing for cross validation'):\n",
    "        for target in range(1, config.num_classes):\n",
    "            if len(train_df.loc[(train_df.Image_ID==image_id) & (train_df.DiseaseClass==int(target))]) > 0:\n",
    "                class_counts[image_id][target] = 1\n",
    "\n",
    "    return pd.DataFrame(class_counts).T.reset_index().rename(columns={\"index\": \"Image_ID\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20ae3432",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T19:31:21.776936Z",
     "iopub.status.busy": "2025-02-06T19:31:21.776712Z",
     "iopub.status.idle": "2025-02-06T19:31:21.780419Z",
     "shell.execute_reply": "2025-02-06T19:31:21.779624Z"
    },
    "id": "xvnkwjjaNhpY",
    "papermill": {
     "duration": 0.009596,
     "end_time": "2025-02-06T19:31:21.781647",
     "exception": false,
     "start_time": "2025-02-06T19:31:21.772051",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def format_image_id(image_id, ext=\"png\"):\n",
    "    image_id = str(image_id)\n",
    "    if \"ID_\" in image_id and \".\" in image_id:\n",
    "        return image_id\n",
    "    elif \".\" in image_id:\n",
    "        return f\"ID_{int(image_id):06d}\"\n",
    "    elif \"ID_\" in image_id:\n",
    "        return f\"{image_id}.{ext}\"\n",
    "    else:\n",
    "        return f\"ID_{int(image_id):06d}.{ext}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "087b55eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T19:31:21.790785Z",
     "iopub.status.busy": "2025-02-06T19:31:21.790527Z",
     "iopub.status.idle": "2025-02-06T19:31:21.794260Z",
     "shell.execute_reply": "2025-02-06T19:31:21.793483Z"
    },
    "id": "lbsTANJcNhpY",
    "papermill": {
     "duration": 0.009425,
     "end_time": "2025-02-06T19:31:21.795349",
     "exception": false,
     "start_time": "2025-02-06T19:31:21.785924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def move_images(dest_dir, df):\n",
    "    os.makedirs(dest_dir, exist_ok=True)\n",
    "    unique_imgs = df.Image_ID.unique()\n",
    "    for img in tqdm(unique_imgs, total=len(unique_imgs), desc=\"Moving images\"):\n",
    "        shutil.copy(os.path.join(config.train_imgs_dir, img), dest_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f524ca1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T19:31:21.804337Z",
     "iopub.status.busy": "2025-02-06T19:31:21.804117Z",
     "iopub.status.idle": "2025-02-06T19:31:21.808584Z",
     "shell.execute_reply": "2025-02-06T19:31:21.807822Z"
    },
    "id": "tVXWBNC5NhpZ",
    "papermill": {
     "duration": 0.010326,
     "end_time": "2025-02-06T19:31:21.809866",
     "exception": false,
     "start_time": "2025-02-06T19:31:21.799540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def decode_bbox(bbox: list, image_path: str):\n",
    "    # Extract image dimensions\n",
    "    with Image.open(image_path) as img:\n",
    "        img_width, img_height = img.size\n",
    "\n",
    "    # Unpack bounding box coordinates\n",
    "    x_min, y_min, x_max, y_max = bbox\n",
    "\n",
    "    # Compute center coordinates, width, and height of the box\n",
    "    xc = (x_min + x_max) / 2\n",
    "    yc = (y_min + y_max) / 2\n",
    "    w = x_max - x_min\n",
    "    h = y_max - y_min\n",
    "\n",
    "    # Normalize values by the image dimensions\n",
    "    xc /= img_width\n",
    "    yc /= img_height\n",
    "    w /= img_width\n",
    "    h /= img_height\n",
    "\n",
    "    # Combine normalized values into a single string\n",
    "    box = np.array([xc, yc, w, h])\n",
    "    return \" \".join(f\"{i:.4g}\" for i in box)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "885dba93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T19:31:21.818909Z",
     "iopub.status.busy": "2025-02-06T19:31:21.818646Z",
     "iopub.status.idle": "2025-02-06T19:31:21.823328Z",
     "shell.execute_reply": "2025-02-06T19:31:21.822525Z"
    },
    "id": "L9FVExsaNhpZ",
    "papermill": {
     "duration": 0.010311,
     "end_time": "2025-02-06T19:31:21.824489",
     "exception": false,
     "start_time": "2025-02-06T19:31:21.814178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_labels(phase, df):\n",
    "    phase = os.path.join(phase, \"labels\")\n",
    "    os.makedirs(phase, exist_ok=True)\n",
    "    unique_imgs = df.Image_ID.unique()\n",
    "    for i, img in tqdm(enumerate(unique_imgs), total=len(unique_imgs), desc=\"Creating labels\"):\n",
    "        df_img = df.loc[df.Image_ID==img]\n",
    "        boxes = [f'{row.DiseaseClass} {decode_bbox(row[[\"xmin\", \"ymin\", \"xmax\", \"ymax\"]],os.path.join(config.train_imgs_dir,img))}' for _, row in df_img.iterrows()]\n",
    "        with open(os.path.join(phase,os.path.splitext(img)[0] + \".txt\"), \"w\") as f:\n",
    "            for box in boxes:\n",
    "                f.write(box + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f85fb935",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T19:31:21.834094Z",
     "iopub.status.busy": "2025-02-06T19:31:21.833870Z",
     "iopub.status.idle": "2025-02-06T19:31:21.837583Z",
     "shell.execute_reply": "2025-02-06T19:31:21.836996Z"
    },
    "id": "Tg7cIRivNhpZ",
    "papermill": {
     "duration": 0.009983,
     "end_time": "2025-02-06T19:31:21.838774",
     "exception": false,
     "start_time": "2025-02-06T19:31:21.828791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_prediction(model, image_id, phase=\"val\"):\n",
    "    if phase == \"val\":\n",
    "        path = config.train_imgs_dir\n",
    "    else:\n",
    "        path = config.test_imgs_dir\n",
    "    pred = model.predict(os.path.join(path,image_id), imgsz=config.img_res, conf=0.3, augment=False, agnostic_nms=True)\n",
    "    pred = json.loads(pred[0].tojson())\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05f3931d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T19:31:21.848030Z",
     "iopub.status.busy": "2025-02-06T19:31:21.847801Z",
     "iopub.status.idle": "2025-02-06T19:31:21.854655Z",
     "shell.execute_reply": "2025-02-06T19:31:21.853916Z"
    },
    "id": "N0yz2O12NhpZ",
    "papermill": {
     "duration": 0.013001,
     "end_time": "2025-02-06T19:31:21.855897",
     "exception": false,
     "start_time": "2025-02-06T19:31:21.842896",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def intersection_over_union(boxes_preds, boxes_labels, box_format=\"midpoint\"):\n",
    "    \"\"\"\n",
    "    Calculates intersection over union\n",
    "\n",
    "    Parameters:\n",
    "        boxes_preds (tensor): Predictions of Bounding Boxes (BATCH_SIZE, 4)\n",
    "        boxes_labels (tensor): Correct Labels of Boxes (BATCH_SIZE, 4)\n",
    "        box_format (str): midpoint/corners, if boxes (x,y,w,h) or (x1,y1,x2,y2)\n",
    "\n",
    "    Returns:\n",
    "        tensor: Intersection over union for all examples\n",
    "    \"\"\"\n",
    "\n",
    "    # Slicing idx:idx+1 in order to keep tensor dimensionality\n",
    "    # Doing ... in indexing if there would be additional dimensions\n",
    "    # Like for Yolo algorithm which would have (N, S, S, 4) in shape\n",
    "    if box_format == \"midpoint\":\n",
    "        box1_x1 = boxes_preds[..., 0:1] - boxes_preds[..., 2:3] / 2\n",
    "        box1_y1 = boxes_preds[..., 1:2] - boxes_preds[..., 3:4] / 2\n",
    "        box1_x2 = boxes_preds[..., 0:1] + boxes_preds[..., 2:3] / 2\n",
    "        box1_y2 = boxes_preds[..., 1:2] + boxes_preds[..., 3:4] / 2\n",
    "        box2_x1 = boxes_labels[..., 0:1] - boxes_labels[..., 2:3] / 2\n",
    "        box2_y1 = boxes_labels[..., 1:2] - boxes_labels[..., 3:4] / 2\n",
    "        box2_x2 = boxes_labels[..., 0:1] + boxes_labels[..., 2:3] / 2\n",
    "        box2_y2 = boxes_labels[..., 1:2] + boxes_labels[..., 3:4] / 2\n",
    "\n",
    "    elif box_format == \"corners\":\n",
    "        box1_x1 = boxes_preds[..., 0:1]\n",
    "        box1_y1 = boxes_preds[..., 1:2]\n",
    "        box1_x2 = boxes_preds[..., 2:3]\n",
    "        box1_y2 = boxes_preds[..., 3:4]\n",
    "        box2_x1 = boxes_labels[..., 0:1]\n",
    "        box2_y1 = boxes_labels[..., 1:2]\n",
    "        box2_x2 = boxes_labels[..., 2:3]\n",
    "        box2_y2 = boxes_labels[..., 3:4]\n",
    "\n",
    "    x1 = torch.max(box1_x1, box2_x1)\n",
    "    y1 = torch.max(box1_y1, box2_y1)\n",
    "    x2 = torch.min(box1_x2, box2_x2)\n",
    "    y2 = torch.min(box1_y2, box2_y2)\n",
    "\n",
    "    # Need clamp(0) in case they do not intersect, then we want intersection to be 0\n",
    "    intersection = (x2 - x1).clamp(0) * (y2 - y1).clamp(0)\n",
    "    box1_area = abs((box1_x2 - box1_x1) * (box1_y2 - box1_y1))\n",
    "    box2_area = abs((box2_x2 - box2_x1) * (box2_y2 - box2_y1))\n",
    "\n",
    "    return intersection / (box1_area + box2_area - intersection + 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4f87153",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T19:31:21.864800Z",
     "iopub.status.busy": "2025-02-06T19:31:21.864569Z",
     "iopub.status.idle": "2025-02-06T19:31:21.872876Z",
     "shell.execute_reply": "2025-02-06T19:31:21.872102Z"
    },
    "id": "qwtRVyYPNhpZ",
    "papermill": {
     "duration": 0.013961,
     "end_time": "2025-02-06T19:31:21.874015",
     "exception": false,
     "start_time": "2025-02-06T19:31:21.860054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mean_average_precision(\n",
    "    pred_boxes, true_boxes, iou_threshold=0.5, box_format=\"corners\", num_classes=15\n",
    "):\n",
    "\n",
    "    # list storing all AP for respective classes\n",
    "    average_precisions = []\n",
    "\n",
    "    # used for numerical stability later on\n",
    "    epsilon = 1e-6\n",
    "\n",
    "    for c in range(num_classes):\n",
    "        detections = []\n",
    "        ground_truths = []\n",
    "\n",
    "        # Go through all predictions and targets,\n",
    "        # and only add the ones that belong to the\n",
    "        # current class c\n",
    "        for detection in pred_boxes:\n",
    "            if detection[1] == c:\n",
    "                detections.append(detection)\n",
    "\n",
    "        for true_box in true_boxes:\n",
    "            if true_box[1] == c:\n",
    "                ground_truths.append(true_box)\n",
    "\n",
    "        # find the amount of bboxes for each training example\n",
    "        # Counter here finds how many ground truth bboxes we get\n",
    "        # for each training example, so let's say img 0 has 3,\n",
    "        # img 1 has 5 then we will obtain a dictionary with:\n",
    "        # amount_bboxes = {0:3, 1:5}\n",
    "        amount_bboxes = Counter([gt[0] for gt in ground_truths])\n",
    "\n",
    "        # We then go through each key, val in this dictionary\n",
    "        # and convert to the following (w.r.t same example):\n",
    "        # ammount_bboxes = {0:torch.tensor[0,0,0], 1:torch.tensor[0,0,0,0,0]}\n",
    "        for key, val in amount_bboxes.items():\n",
    "            amount_bboxes[key] = torch.zeros(val)\n",
    "\n",
    "        # sort by box probabilities which is index 2\n",
    "        detections.sort(key=lambda x: x[2], reverse=True)\n",
    "        TP = torch.zeros((len(detections)))\n",
    "        FP = torch.zeros((len(detections)))\n",
    "        total_true_bboxes = len(ground_truths)\n",
    "\n",
    "        # If none exists for this class then we can safely skip\n",
    "        if total_true_bboxes == 0:\n",
    "            continue\n",
    "\n",
    "        for detection_idx, detection in enumerate(detections):\n",
    "            # Only take out the ground_truths that have the same\n",
    "            # training idx as detection\n",
    "            ground_truth_img = [\n",
    "                bbox for bbox in ground_truths if bbox[0] == detection[0]\n",
    "            ]\n",
    "\n",
    "            num_gts = len(ground_truth_img)\n",
    "            best_iou = 0\n",
    "\n",
    "            for idx, gt in enumerate(ground_truth_img):\n",
    "                iou = intersection_over_union(\n",
    "                    torch.tensor(detection[3:]),\n",
    "                    torch.tensor(gt[2:]),\n",
    "                    box_format=box_format,\n",
    "                )\n",
    "\n",
    "                if iou > best_iou:\n",
    "                    best_iou = iou\n",
    "                    best_gt_idx = idx\n",
    "\n",
    "            if best_iou > iou_threshold:\n",
    "                # only detect ground truth detection once\n",
    "                if amount_bboxes[detection[0]][best_gt_idx] == 0:\n",
    "                    # true positive and add this bounding box to seen\n",
    "                    TP[detection_idx] = 1\n",
    "                    amount_bboxes[detection[0]][best_gt_idx] = 1\n",
    "                else:\n",
    "                    FP[detection_idx] = 1\n",
    "\n",
    "            # if IOU is lower then the detection is a false positive\n",
    "            else:\n",
    "                FP[detection_idx] = 1\n",
    "\n",
    "        TP_cumsum = torch.cumsum(TP, dim=0)\n",
    "        FP_cumsum = torch.cumsum(FP, dim=0)\n",
    "        recalls = TP_cumsum / (total_true_bboxes + epsilon)\n",
    "        precisions = TP_cumsum / (TP_cumsum + FP_cumsum + epsilon)\n",
    "        precisions = torch.cat((torch.tensor([1]), precisions))\n",
    "        recalls = torch.cat((torch.tensor([0]), recalls))\n",
    "        # torch.trapz for numerical integration\n",
    "        average_precisions.append(torch.trapz(precisions, recalls))\n",
    "\n",
    "    return sum(average_precisions) / len(average_precisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40b8729c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T19:31:21.882724Z",
     "iopub.status.busy": "2025-02-06T19:31:21.882477Z",
     "iopub.status.idle": "2025-02-06T19:31:21.887384Z",
     "shell.execute_reply": "2025-02-06T19:31:21.886617Z"
    },
    "id": "jCLgH5PjNhpZ",
    "papermill": {
     "duration": 0.010583,
     "end_time": "2025-02-06T19:31:21.888605",
     "exception": false,
     "start_time": "2025-02-06T19:31:21.878022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, val_df):\n",
    "    transformed_pred = []\n",
    "\n",
    "    for image_id in tqdm(val_df[\"Image_ID\"].unique(), desc=\"Evaluating\"):\n",
    "        pred = get_prediction(model, image_id)\n",
    "        for item in pred:\n",
    "            transformed_pred.append({\n",
    "                'Image_ID': image_id,\n",
    "                'DiseaseClass': item['class'],\n",
    "                'confidence': item['confidence'],\n",
    "                'Xmin': item['box']['x1'],\n",
    "                'Ymin': item['box']['y1'],\n",
    "                'Xmax': item['box']['x2'],\n",
    "                'Ymax': item['box']['y2']\n",
    "            })\n",
    "    transformed_pred_ = [[v for v in pred.values()] for pred in transformed_pred]\n",
    "    val_df_ = [row.values.tolist() for _, row in val_df.iterrows()]\n",
    "    mAP = mean_average_precision(transformed_pred_, val_df_, num_classes=config.num_classes)\n",
    "    transformed_pred = pd.DataFrame(transformed_pred)\n",
    "\n",
    "    return mAP.item(), transformed_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4165f8ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T19:31:21.897456Z",
     "iopub.status.busy": "2025-02-06T19:31:21.897235Z",
     "iopub.status.idle": "2025-02-06T19:31:21.901310Z",
     "shell.execute_reply": "2025-02-06T19:31:21.900753Z"
    },
    "id": "1UnegW2MNhpZ",
    "papermill": {
     "duration": 0.009801,
     "end_time": "2025-02-06T19:31:21.902457",
     "exception": false,
     "start_time": "2025-02-06T19:31:21.892656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_prediction(model, ss):\n",
    "    unique_imgs = ss[\"Image_ID\"].unique()\n",
    "    transformed_pred = []\n",
    "    for image_id in tqdm(unique_imgs, total=len(unique_imgs), desc=\"Generaing predictions\"):\n",
    "        pred = get_prediction(model, image_id, phase=\"test\")\n",
    "        for item in pred:\n",
    "            transformed_pred.append({\n",
    "                'Image_ID': image_id,\n",
    "                'DiseaseClass': int(item['name']),\n",
    "                'confidence': item['confidence'],\n",
    "                'Xmin': item['box']['x1'],\n",
    "                'Ymin': item['box']['y1'],\n",
    "                'Xmax': item['box']['x2'],\n",
    "                'Ymax': item['box']['y2']\n",
    "            })\n",
    "    transformed_pred = pd.DataFrame(transformed_pred)\n",
    "    return transformed_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d16d5ff2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T19:31:21.911408Z",
     "iopub.status.busy": "2025-02-06T19:31:21.911189Z",
     "iopub.status.idle": "2025-02-06T19:31:22.163111Z",
     "shell.execute_reply": "2025-02-06T19:31:22.162175Z"
    },
    "id": "cn-NAMgtNhpZ",
    "papermill": {
     "duration": 0.257998,
     "end_time": "2025-02-06T19:31:22.164621",
     "exception": false,
     "start_time": "2025-02-06T19:31:21.906623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(os.path.join(config.base_dir, \"Train.csv\"))\n",
    "ss = pd.read_csv(os.path.join(config.base_dir, \"SampleSubmission.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d381bc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T19:31:22.174290Z",
     "iopub.status.busy": "2025-02-06T19:31:22.174046Z",
     "iopub.status.idle": "2025-02-06T19:31:22.177380Z",
     "shell.execute_reply": "2025-02-06T19:31:22.176779Z"
    },
    "papermill": {
     "duration": 0.009418,
     "end_time": "2025-02-06T19:31:22.178569",
     "exception": false,
     "start_time": "2025-02-06T19:31:22.169151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_labels(row):\n",
    "    if row[\"DiseaseClass\"].endswith(\"Mosaic\"):\n",
    "        return \"Mosaic\"\n",
    "    elif row[\"DiseaseClass\"] == \"Healthy\":\n",
    "        return row['class']\n",
    "    else:\n",
    "        return row[\"DiseaseClass\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d186e9b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T19:31:22.187564Z",
     "iopub.status.busy": "2025-02-06T19:31:22.187354Z",
     "iopub.status.idle": "2025-02-06T19:31:22.614620Z",
     "shell.execute_reply": "2025-02-06T19:31:22.613975Z"
    },
    "id": "zNOhKaA3NhpZ",
    "papermill": {
     "duration": 0.433442,
     "end_time": "2025-02-06T19:31:22.616285",
     "exception": false,
     "start_time": "2025-02-06T19:31:22.182843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train['DiseaseClass'] = train['class'].apply(lambda x: '_'.join(x.split('_')[1:]))\n",
    "train['DiseaseClass'] = train.apply(get_labels, axis=1)\n",
    "train = train.loc[~train['class'].str.startswith('Corn')].reset_index(drop=True)\n",
    "train = train.drop('class', axis=1).drop_duplicates(ignore_index=True)\n",
    "train_df = train.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d016d40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T19:31:22.626214Z",
     "iopub.status.busy": "2025-02-06T19:31:22.625994Z",
     "iopub.status.idle": "2025-02-06T19:31:22.632651Z",
     "shell.execute_reply": "2025-02-06T19:31:22.631927Z"
    },
    "papermill": {
     "duration": 0.012816,
     "end_time": "2025-02-06T19:31:22.633865",
     "exception": false,
     "start_time": "2025-02-06T19:31:22.621049",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3493"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Image_ID.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44bef6f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T19:31:22.643153Z",
     "iopub.status.busy": "2025-02-06T19:31:22.642953Z",
     "iopub.status.idle": "2025-02-06T22:50:43.644945Z",
     "shell.execute_reply": "2025-02-06T22:50:43.644077Z"
    },
    "id": "bL3YRHurNhpZ",
    "outputId": "e67be8eb-b1f9-4343-c124-4eeacaf2f095",
    "papermill": {
     "duration": 11961.008494,
     "end_time": "2025-02-06T22:50:43.646603",
     "exception": false,
     "start_time": "2025-02-06T19:31:22.638109",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes: {0: 'Bacterial_Spot', 1: 'Fusarium', 2: 'Early_Blight', 3: 'Septoria', 4: 'Leaf_Curl', 5: 'Mosaic', 6: 'Pepper_Healthy', 7: 'Tomato_Healthy', 8: 'Late_Blight', 9: 'Cercospora', 10: 'Leaf_Blight'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing for cross validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3493/3493 [01:18<00:00, 44.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------Training Fold 1/5---------------------------------\n",
      "Training Data: 23710 - unique: 3318\n",
      "Validating Data: 1215 - unique: 175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Moving images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3318/3318 [01:56<00:00, 28.38it/s]\n",
      "Moving images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 175/175 [00:05<00:00, 30.86it/s]\n",
      "Creating labels: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3318/3318 [00:37<00:00, 87.85it/s] \n",
      "Creating labels: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 175/175 [00:01<00:00, 93.38it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8m.pt to 'yolov8m.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 49.7M/49.7M [00:00<00:00, 255MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.72 ðŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15095MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.pt, data=/kaggle/working/data.yaml, epochs=40, time=None, patience=20, batch=12, imgsz=1024, save=True, save_period=-1, cache=False, device=[0], workers=8, project=None, name=Yolo_M_fold_0, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=42, deterministic=True, single_cls=False, rect=False, cos_lr=True, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.5, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.2, hsv_v=0.1, degrees=0.2, translate=0.1, scale=0.2, shear=0.1, perspective=0.0, flipud=0.2, fliplr=0.2, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.3, crop_fraction=0.3, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/Yolo_M_fold_0\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 18.1MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=11\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3782065  ultralytics.nn.modules.head.Detect           [11, [192, 384, 576]]         \n",
      "Model summary: 295 layers, 25,862,689 parameters, 25,862,673 gradients, 79.1 GFLOPs\n",
      "\n",
      "Transferred 469/475 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/Yolo_M_fold_0', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.35M/5.35M [00:00<00:00, 76.0MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/train/labels... 3318 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3318/3318 [00:02<00:00, 1173.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/val/labels... 175 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 175/175 [00:00<00:00, 1085.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/val/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/Yolo_M_fold_0/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000667, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.00046875), 83 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
      "Image sizes 1024 train, 1024 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/Yolo_M_fold_0\u001b[0m\n",
      "Starting training for 40 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/40      13.3G      2.158      3.452      1.781         63       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [04:43<00:00,  1.02s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        175       1215      0.343      0.254      0.156     0.0591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/40      12.6G      2.102      2.653      1.711         74       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [04:46<00:00,  1.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:05<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        175       1215      0.287      0.218      0.153     0.0615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/40      12.5G      2.109      2.524      1.718         69       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [04:45<00:00,  1.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:05<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        175       1215      0.373      0.237      0.175     0.0713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/40      12.5G      2.109      2.497      1.724         44       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [04:43<00:00,  1.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        175       1215      0.295      0.253      0.178     0.0733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/40      12.6G      2.069      2.404      1.683         54       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [04:45<00:00,  1.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:05<00:00,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        175       1215      0.396      0.344      0.254      0.105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/40      12.5G      2.033      2.324      1.664         52       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [04:44<00:00,  1.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:05<00:00,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        175       1215      0.327      0.314       0.23     0.0968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/40      12.6G      2.024      2.254      1.662         83       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [04:43<00:00,  1.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        175       1215      0.415      0.316      0.276      0.118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/40      12.6G      2.014      2.224      1.661         43       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [04:44<00:00,  1.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        175       1215      0.424      0.353        0.3      0.126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/40      12.5G      1.998      2.164      1.628         62       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [04:44<00:00,  1.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        175       1215      0.367      0.382      0.277      0.114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/40      12.7G      1.962       2.11      1.622         89       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [04:45<00:00,  1.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        175       1215      0.423      0.353      0.306      0.131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/40      12.7G      1.954      2.077      1.601         56       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [04:44<00:00,  1.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        175       1215      0.489      0.373       0.33      0.141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/40      12.5G       1.95      2.039      1.598         71       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [04:44<00:00,  1.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        175       1215      0.366      0.365      0.324      0.144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/40      12.6G      1.913      1.985      1.581         55       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [04:44<00:00,  1.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        175       1215      0.412      0.395      0.338       0.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/40      12.6G      1.887      1.913       1.56         56       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [04:43<00:00,  1.02s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:05<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        175       1215      0.328       0.41      0.358      0.156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/40      12.4G      1.878      1.889      1.551        103       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [04:45<00:00,  1.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:05<00:00,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        175       1215      0.434      0.417      0.359      0.159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/40      12.5G      1.865      1.861      1.553         60       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [04:44<00:00,  1.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        175       1215      0.353      0.403       0.36      0.156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/40      12.4G      1.821      1.775      1.513         75       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [04:43<00:00,  1.02s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:05<00:00,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        175       1215      0.387       0.42      0.375      0.165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/40      12.6G      1.842      1.772       1.53         52       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [04:43<00:00,  1.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:05<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        175       1215      0.571      0.382      0.398      0.175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/40      12.6G       1.82       1.72      1.506         56       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [04:44<00:00,  1.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        175       1215       0.45      0.436      0.378      0.167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/40      12.6G      1.813      1.688      1.495         62       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [04:44<00:00,  1.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        175       1215      0.421      0.416       0.39      0.173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/40      12.5G       1.78      1.623      1.482         44       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [04:44<00:00,  1.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        175       1215       0.41      0.459        0.4      0.175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/40      12.5G      1.745      1.565      1.459         27       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [04:45<00:00,  1.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:05<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        175       1215      0.413      0.464      0.409       0.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/40      12.6G       1.74      1.546      1.457         60       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [04:44<00:00,  1.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        175       1215      0.469      0.426      0.415      0.183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/40      12.6G      1.718      1.487      1.445         55       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [04:44<00:00,  1.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        175       1215      0.445      0.485       0.42      0.186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/40      12.4G      1.685      1.455      1.427         33       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [04:44<00:00,  1.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        175       1215      0.447      0.429      0.414      0.184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/40      12.6G      1.664      1.409      1.417         71       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [04:44<00:00,  1.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        175       1215      0.461      0.459      0.432      0.194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/40        13G      1.675      1.404      1.413         86       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [04:44<00:00,  1.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        175       1215      0.474      0.448      0.422      0.188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/40      12.6G      1.629      1.343      1.398         67       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [04:44<00:00,  1.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        175       1215      0.487      0.452      0.443      0.197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/40      12.6G       1.64       1.33       1.39        111       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [04:43<00:00,  1.02s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        175       1215      0.487      0.448      0.434      0.191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/40      12.6G      1.582      1.273      1.376         98       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [04:43<00:00,  1.02s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        175       1215      0.491      0.462      0.448      0.197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      31/40      12.7G      1.584      1.221      1.361         30       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [04:45<00:00,  1.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        175       1215      0.501      0.465       0.45      0.193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      32/40      12.5G      1.545       1.15      1.346         55       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [04:42<00:00,  1.02s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        175       1215      0.517      0.436      0.447        0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      33/40      12.7G      1.527      1.123      1.332        101       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [04:42<00:00,  1.02s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        175       1215      0.538      0.454      0.452      0.197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/40      12.6G      1.517      1.113      1.328         72       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [04:41<00:00,  1.02s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        175       1215      0.499      0.473      0.462      0.199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      35/40      12.5G      1.505      1.082      1.319         52       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [04:42<00:00,  1.02s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        175       1215      0.486      0.483       0.45      0.198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      36/40      12.4G      1.491      1.069      1.315         54       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [04:43<00:00,  1.02s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        175       1215      0.507      0.488       0.46      0.201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      37/40      12.5G      1.481      1.057      1.308         57       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [04:42<00:00,  1.02s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        175       1215      0.505      0.476      0.453      0.197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      38/40      12.5G      1.485      1.052      1.312         77       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [04:43<00:00,  1.02s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        175       1215      0.526      0.459      0.457      0.199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      39/40      12.5G      1.465      1.026      1.299         51       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [04:42<00:00,  1.02s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        175       1215      0.521      0.472      0.462      0.199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      40/40      12.5G       1.47      1.037      1.299         29       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [04:43<00:00,  1.02s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        175       1215      0.522      0.466      0.461      0.199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "40 epochs completed in 3.241 hours.\n",
      "Optimizer stripped from runs/detect/Yolo_M_fold_0/weights/last.pt, 52.1MB\n",
      "Optimizer stripped from runs/detect/Yolo_M_fold_0/weights/best.pt, 52.1MB\n",
      "\n",
      "Validating runs/detect/Yolo_M_fold_0/weights/best.pt...\n",
      "Ultralytics 8.3.72 ðŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15095MiB)\n",
      "Model summary (fused): 218 layers, 25,846,129 parameters, 0 gradients, 78.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        175       1215      0.506      0.488       0.46      0.201\n",
      "Speed: 0.4ms preprocess, 21.5ms inference, 0.0ms loss, 4.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/Yolo_M_fold_0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "config.classes = train.DiseaseClass.unique().tolist()\n",
    "config.num_classes = len(config.classes)\n",
    "config.id2cls = {k:v for k, v in enumerate(config.classes)}\n",
    "config.cls2id = {v:k for k, v in enumerate(config.classes)}\n",
    "print(f\"classes: {config.id2cls}\")\n",
    "\n",
    "train[\"DiseaseClass\"] = train[\"DiseaseClass\"].map(config.cls2id)\n",
    "\n",
    "class_counts = get_class_counts(train)\n",
    "\n",
    "def get_new_labels(y):\n",
    "    y_new = LabelEncoder().fit_transform([''.join(str(l)) for l in y.values])\n",
    "    return y_new\n",
    "\n",
    "y_new = get_new_labels(class_counts[range(1, config.num_classes+1)])\n",
    "\n",
    "folds = StratifiedKFold(n_splits=config.n_folds, shuffle=True, random_state=config.training_params[\"seed\"])\n",
    "class_counts['fold'] = -1\n",
    "for i, (train_index, test_index) in enumerate(folds.split(class_counts, y=y_new)):\n",
    "    class_counts.loc[test_index,'fold'] = i\n",
    "\n",
    "with open(\"/kaggle/working/data.yaml\", \"w\") as f:\n",
    "    json.dump({\"train\": \"train\", \"val\": \"val\", \"nc\": config.num_classes, \"names\": config.classes}, f)\n",
    "\n",
    "cv_scores = []\n",
    "preds = []\n",
    "for fold in range(config.n_folds):\n",
    "    if fold not in config.selected_folds:\n",
    "        continue\n",
    "    print(f'--------------------------------Training Fold {fold+1}/5---------------------------------')\n",
    "    train_ids = class_counts[class_counts.fold!=fold].reset_index(drop=True)\n",
    "    valid_ids = class_counts[class_counts.fold==fold].reset_index(drop=True)\n",
    "\n",
    "    train_ = train.loc[train.Image_ID.isin(train_ids.Image_ID.values)]\n",
    "    val_ = train.loc[train.Image_ID.isin(valid_ids.Image_ID.values)]\n",
    "\n",
    "    print(f\"Training Data: {len(train_)} - unique: {train_.Image_ID.nunique()}\")\n",
    "    print(f\"Validating Data: {len(val_)} - unique: {val_.Image_ID.nunique()}\")\n",
    "\n",
    "    train_dir = os.path.join(\"/kaggle/working/train\", \"images\")\n",
    "    val_dir = os.path.join(\"/kaggle/working/val\", \"images\")\n",
    "    move_images(train_dir, train_)\n",
    "    move_images(val_dir, val_)\n",
    "\n",
    "    create_labels(\"/kaggle/working/train\", train_)\n",
    "    create_labels(\"/kaggle/working/val\", val_)\n",
    "\n",
    "    model = YOLO(config.model_name)\n",
    "    model.train(data=\"/kaggle/working/data.yaml\", task=\"detect\", imgsz=config.img_res, val=True,\n",
    "                \n",
    "                name=f\"Yolo_M_fold_{fold}\", **config.training_params)\n",
    "\n",
    "    model.save(\"non_corn_yolo_11_nano_40_epoch.pt\")\n",
    "    \n",
    "    # score, preds_df = evaluate_model(model, val_)\n",
    "    # cv_scores.append(score)\n",
    "    # preds.append(generate_prediction(model, ss))\n",
    "\n",
    "    # Remove directories\n",
    "    shutil.rmtree(\"train\")\n",
    "    shutil.rmtree(\"val\")\n",
    "    # print(f\"Score on fold {fold}: {score}\")\n",
    "\n",
    "# print(f\"cv score: {np.mean(cv_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da3c6365",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T22:50:46.053290Z",
     "iopub.status.busy": "2025-02-06T22:50:46.052985Z",
     "iopub.status.idle": "2025-02-06T22:50:46.056359Z",
     "shell.execute_reply": "2025-02-06T22:50:46.055760Z"
    },
    "id": "Pqz92WZtNhpa",
    "papermill": {
     "duration": 1.266198,
     "end_time": "2025-02-06T22:50:46.057638",
     "exception": false,
     "start_time": "2025-02-06T22:50:44.791440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Max MAP50: 0.42 close mosaic=20 / without any augmentations\n",
    "## Max MAP50: - 0.40 close mosaic=10 / with augmentations mosaic 0.15-0.30 / 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc58c36c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T22:50:48.413759Z",
     "iopub.status.busy": "2025-02-06T22:50:48.413414Z",
     "iopub.status.idle": "2025-02-06T22:50:48.416591Z",
     "shell.execute_reply": "2025-02-06T22:50:48.415807Z"
    },
    "papermill": {
     "duration": 1.224875,
     "end_time": "2025-02-06T22:50:48.418080",
     "exception": false,
     "start_time": "2025-02-06T22:50:47.193205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from IPython.display import FileLink\n",
    "\n",
    "# FileLink('runs/detect/Yolo_M_fold_0/weights/best.pt')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6275743,
     "sourceId": 10162881,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5864929,
     "sourceId": 9611596,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11993.916933,
   "end_time": "2025-02-06T22:50:53.079542",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-06T19:30:59.162609",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
